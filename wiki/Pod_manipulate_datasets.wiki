#summary Converted POD documentation.
#labels ManPage
_This page was generated from POD using [http://code.google.com/p/pod2gcw pod2gcw] and is not intended for editing._

==NAME==
manipulate_datasets.pl

A progam to manipulate tab-delimited dataset files and avoid !ExcHell**.

==SYNOPSIS==
manipulate_datasets.pl `[`--options ...`]` <**input_filename>

{{{
  Options:
  --in <input_filename>
  --func [ stat | reorder | delete | rename | number | sort | gsort | 
          null | duplicate | above | below | cnull | absolute | minimum | 
          maximum | add | subtract | multiply | divide | scale | pr | 
          zscore | log2 | delog2 | format | combine | subsample | ratio | 
          diff | normdiff | strandsign | mergestrand | center | new | 
          summary | export | rewrite | treeview ]
  --index <integers>
  --exp <integer>
  --con <integer>
  --target <text> or <number>
  --place [r | n]
  --except [y | n]
  --dir [i | d]
  --name <text>
  --out <filename>
  --(no)log
  --(no)gz
  --version
  --help
  --doc
}}}
==OPTIONS==
The command line flags and descriptions:

__--in <**input_filename>

__
  Provide the name of an input file. The file must be a tab-delimited text file, with each row  specifiying a genomic feature (gene) or region, and each column representing identifying  information or a dataset value. The first row should include the name for each column, e.g. the name of the database dataset from which the values were collected.
__
  __
  If the file was generated using 'get_datasets.pl' and/or uses Tim's data file format, then each  column will have metadata stored in a header comment line at the beginning of the file. This line is prefixed with a # and is comprised of key=value pairs demarcated by semi-colons. Manipulations  on the data in a column dataset will be added to this metadata and recorded upon file write.
__
  __
  If no metadata is present in the file, then it will be automatically generated with minimal  information upon opening the file.
__
  __
  The input file may be compressed using the gzip program and recognized with the extension '.gz'. It  will be automatically decompressed upon reading.
__
  __
__--func <**function>

__
  The program is designed to be run interactively. However, single manipulations  may be performed on single datasets by specifying a function name and any  other required options. These functions include the following.
__
  __
{{{
  stat
  reorder
  delete
  rename
  number
  sort
  gsort
  null
  duplicate
  above
  below
  cnull
  absolute
  minimum
  maximum
  add
  subtract
  multiply
  divide
  scale
  pr
  zscore
  log2
  delog2
  format
  combine
  subsample
  ratio
  diff
  normdiff
  strandsign
  mergestrand
  center
  new
  summary
  export
  rewrite
  treeview
}}}
  Refer to the FUNCTIONS section for details.
__
  __
__--index <**integers>

__
  Provide the 0-based index number of the column(s) on which to perform the  function(s). Multiple indices may also be specified using a comma delimited  list without spaces. Ranges of contiguous indices may be specified using a  dash between the start and stop. For example, '1,2,5-7,9' would indicate  datasets '1, 2, 5, 6, 7, and 9'.
__
  __
__--exp | --num <**integer>

__
  Specify the 0-based index number to be used for the experiment or numerator  dataset with the 'ratio' or 'difference' functions. Both flags are aliases for the same thing.
__
  __
__--con | --den <**integer>

__
  Specify the 0-based index number to be used for the control or denominator  dataset with the 'ratio' or 'difference' functions. Both flags are aliases for the same thing.
__
  __
__--target <**string> or <**number>

__
  Specify the target value when using various functions. This is a catch-all  option for a number of functions. Please refer to the function description  for more information.
__
  __
__--place `[`r | n`]`

__
  Specify the placement of a transformed dataset. Two values are accepted ('r'  or 'n'):
__
  __
{{{
  - (r)eplace the original dataset with the new one
  - add as a (n)ew dataset
}}}
  Defaults to new placement when executed automatically using the --func  option, or prompts the user when executed interactively.
__
  __
__--except `[`y | n`]`

__
  Specify what to do when a calculation encounters a 0 value. Two exception  values are accepted:
__
  __
{{{
  - (y)es, include 0 values in the calculation
  - (n)o, do not include 0 values in the calculation
  }}}
  If this is not specified, the program will ask interactively if this occurs.
__
  __
__--dir `[`i | d`]`

__
  Specify the direction of a sort:
__
  __
{{{
  - (i)ncreasing
  - (d)ecreasing
  }}}
__--name <**string>

__
  Specify a new dataset name when re-naming a dataset using the rename function  from the command line. Also, when generating a new dataset using a defined  function (--func <**function>) from the command line, the new dataset will use  this name.
__
  __
__--out <**filename>

__
  Optionally provide an alternative output file name. If no name is provided, then the input file  will be overwritten with a new file. Appropriate extensions will be appended as necessary.
__
  __
__--(no)log

__
  Indicate whether the data is (not) in log2 space. This is required to ensure accurate mathematical  calculations in some manipulations. This is not necessary when the log status is appropriately  recorded in the dataset metadata.
__
  __
__--(no)gz

__
  Indicate whether the output file should (not) be compressed. The appropriate extension will be  added. If this option is not specified, then the compression status of the input file will be  preserved.
__
  __
__--version

__
  Print the version number.
__
  __
__--help

__
  Display the POD documentation using perldoc.
__
  __
==DESCRIPTION==
This program allows some common mathematical and other manipulations on one or more datasets in a datafile. The program is designed as a simple replacement for common manipulations performed in a full featured spreadsheet program, e.g. Excel, particularly with datasets too large to be loaded, all in a conveniant command line program. The program is designed to be operated primarily as an interactive program, allowing for multiple manipulations to be performed. Alternatively, single manipulations may be performed as specified using command line options. As such, the program can be called in shell scripts.

Note that the datafile is loaded entirely in memory. For extremely large  datafiles, e.g. binned genomic data, it may be best to first split the  file into chunks (use `split_data_file.pl`), perform the manipulations,  and recombine the file (use `join_data_file.pl`). This could be done  through a simple shell script.

The program keeps track of the number of manipulations performed, and if  any are performed, will write out to file the changed data. Unless an  output file name is provided, it will overwrite the input file (NO BACKUP is made!).

==FUNCTIONS==
This is a list of the functions available for manipulating datasets. These may  be selected interactively from the main menu (note the case sensitivity!),  or specified on the command line using the --func option.

_*_stat_*_ (menu option 't')

__
  Print some basic statistics for a dataset, including mean,  median, standard deviation, min, and max. If 0 values are present, indicate whether to include them (y or n)
__
  __
_*_reorder_*_ (menu option 'R')

__
  The datasets may be rewritten in a different order. The new order  is requested as a string of index numbers in the desired order.  Also, a dataset may be deleted by skipping its number or duplicated by including it twice.
__
  __
_*_delete_*_ (menu option 'D')

__
  One or more datasets may be selected for deletion.
__
  __
_*_rename_*_ (menu option 'n')

__
  Assign a new name to a dataset. For automatic execution, use the --name  option to specify the new name. Also, for any automatically executed  function (using the --func option) that generates a new dataset, the  dataset's new name may be explicitly defined with this option.
__
  __
_*_number_*_ (menu option 'b')

__
  Assign a number to each datapoint (or line), incrementing from 1  to the end. The numbered dataset will be inserted after the requested  dataset index.
__
  __
_*_sort_*_ (menu option 'o')

__
  The entire data table is sorted by a specific dataset. The first datapoint is checked for the presence of letters, and the data  table is then sorted either asciibetically or numerically. If the  sort method cannot be automatically determined, it will ask. The  direction of sort, (i)ncreasing or (d)ecreasing, is requested.
__
  __
_*_gsort_*_ (menu option 'g')

__
  The entire data table is sorted by increasing genomic position,  first by chromosome then by start position. These columns must exist  and have recognizable names (e.g. 'chromo', 'chromosome', 'start').
__
  __
_*_null_*_ (menu option 'N')

__
  Toss datapoints (rows) that contain a null value in one or more  datasets (columns). Some of the other functions may not work properly if a non-value is present. If 0 values are present, indicate whether to toss them (y or n). This may also be specified as a command line  option using the --except flag.
__
  __
_*_duplicate_*_ (menu option 'P')

__
  Toss datapoints with duplicate values. One or more datasets may be  selected to search for duplicate values. Values are simply concatenated  when multiple datasets are selected. Rows with duplicated values are  deleted, always leaving the first row.
__
  __
_*_above_*_ (menu option 'A')

__
  Toss datapoints with values that are above a certain threshold value.  One or more datasets may be selected to test values for the  threshold. The threshold value may be requested interactively or  specified with the --target option.
__
  __
_*_below_*_ (menu option 'B')

__
  Toss datapoints with values that are below a certain threshold value.  One or more datasets may be selected to test values for the  threshold. The threshold value may be requested interactively or  specified with the --target option.
__
  __
_*_cnull_*_ (menu option 'U')

__
  Convert null values to a specific value. One or more datasets may  be selected to convert null values. The new value may be requested  interactively or defined with the --target option.
__
  __
_*_absolute_*_ (menu option 'L')

__
  Convert signed values to their absolute value equivalents. One or  more datasets may be selected to convert.
__
  __
_*_minimum_*_ (menu option 'I')

__
  Reset datapoints whose values are less than a specified minimum  value to the minimum value. One or more datasets may be selected  to reset values to the minimum. The minimum value may be requested  interactively or specified with the --target option.
__
  __
_*_maximum_*_ (menu option 'X')

__
  Reset datapoints whose values are greater than a specified maximum  value to the maximum value. One or more datasets may be selected  to reset values to the maximum. The maximum value may be requested  interactively or specified with the --target option.
__
  __
_*_add_*_ (menu option 'a')

__
  Add a value to a dataset. A real number may be supplied, or the words 'mean', 'median', or 'sum' may be entered as a proxy for those statistical values of the dataset. The dataset may either be replaced or added as a new one. For automatic execution, specify the number using the --target option.
__
  __
_*_subtract_*_ (menu option 'u')

__
  Subtract a value from a dataset. A real number may be supplied, or the words 'mean', 'median', or 'sum' may be entered as a proxy for those statistical values of the dataset. The dataset may either be replaced or added as a new one. For automatic execution, specify the number using the --target option.
__
  __
_*_multiply_*_ (menu option 'y')

__
  Multiply a dataset by a value. A real number may be supplied, or the words 'mean', 'median', or 'sum' may be entered as a proxy for those statistical values of the dataset. The dataset may either be replaced or added as a new one. For automatic execution, specify the number using the --target option.
__
  __
_*_divide_*_ (menu option 'v')

__
  Divide a dataset by a value. A real number may be supplied, or the words 'mean', 'median', or 'sum' may be entered as a proxy for those statistical values of the dataset. The dataset may either be replaced or added as a new one. For automatic execution, specify the number using the --target option.
__
  __
_*_scale_*_ (menu option 's')

__
  A dataset may be a median scaled as a means of normalization  with other datasets. The current median of the dataset requested is presented, and a new median target is requested. The dataset may  either be replaced with the median scaled values or added as a new  dataset. For automatic execution, specify the new median target  with the --target option.
__
  __
_*_pr_*_ (menu option 'p')

__
  A dataset may be converted to a percentile rank, whereby the data values are sorted in ascending order and assigned a new value  from 0..1 based on its rank in the sorted order. The dataset may  either be replaced with the percentile rank or added as a new dataset. The original order of the dataset is maintained.
__
  __
_*_zscore_*_ (menu option 'Z')

__
  Generate a Z-score or standard score for each value in a dataset. The Z-score is the number of standard deviations the value is away from the dataset's mean, such that the new mean is 0 and the standard  deviation is 1. Provides a simple method of normalizing datasets with disparate dynamic ranges.
__
  __
_*_log2_*_ (menu option 'l')

__
  A dataset may be converted to log base 2 values. The dataset may either be replaced with the log2 values ar added as a new  dataset.
__
  __
_*_delog2_*_ (menu option '2')

__
  A dataset that is currently in log2 space may be converted back to normal base10 numbers. The dataset may either be replaced with the  new values or added as a new dataset.
__
  __
_*_format_*_ (menu option 'f')

__
  Format the numbers of a dataset to a given number of decimal places.  Acceptable numbers of decimal places include 0, 1, 2, or 3. The dataset may either be replaced or added as a new dataset. For  automatic execution, use the --target option to specify the number  decimal places.
__
  __
_*_combine_*_ (menu option 'c')

__
  Mathematically combine the data values in two or more datasets. The  methods for combining the values include mean, median, min, max,  stdev, or sum. The method may be specified on the command line  using the --target option. The combined data values are added as a  new dataset.
__
  __
_*_subsample_*_ (menu option 'su')

__
  Subsample an enumerated dataset. Datapoints within a dataset are chosen  randomly and the values reduced by one until the target sum is reached.  This assumes an enumerated dataset, e.g. tag counts from Next-gen sequencing, where the sum of tags from two or more datasets must be normalized to each other. This function assumes that the data are positive integers; log2 datasets will not be used. Provide a target sum to reach using the --target option. If this number is less than or equal to the number of datasets in the file, then it is assumed to be an index number and the sum of that dataset will be used as the target. The subsampled dataset is always added as new dataset.
__
  __
_*_ratio_*_ (menu option 'r')

__
  A ratio may be generated between two datasets. The experiment and  control datasets are requested and the ratio is added as a new dataset. For log2 numbers, the control is subtracted from the experiment. The log2 status is checked in the metadata for the  specified datasets, or may be specified as a command line option, or asked of the user.
__
  __
_*_diff_*_ (menu option 'd')

__
  A simple difference is generated between two existing datasets. The  values in the 'control' dataset are simply subtracted from the  values in the 'experimental' dataset and recorded as a new dataset. For enumerated datasets (e.g. tag counts from Next Generation  Sequencing), the datasets should be subsampled to equalize the sums  of the two datasets. The indices for the experimental and control datasets  may either requested from the user or supplied by the --exp and  --con command line options.
__
  __
_*_normdiff_*_ (menu option 'z')

__
  A normalized difference is generated between two existing datasets.  The difference between 'control' and 'experimental' dataset values  is divided by the square root of the sum (an approximation of the  standard deviation). This is supposed to yield fewer false positives than a simple difference (see Nix et al, BMC Bioinformatics, 2008). For enumerated datasets (e.g. tag counts from Next Generation  Sequencing), the datasets should be subsampled to equalize the sums  of the two datasets. The indices for the experimental and control datasets  may either requested from the user or supplied by the --exp and  --con command line options.
__
  __
_*_strandsign_*_ (menu option 'si')

__
  Convert a dataset's values to signed data according to strand. Forward  strand data is positive, and reverse strand is negative. This function  may not be appropriate with logarithmic or other datasets that include  negative values. Provide the index of a single dataset to convert. A  second dataset should provide the strand information and be labeled  with a name that includes either 'strand' or 'direction'. Strand  information may include 1, -1, +, -, f, r, w, c, ., or 0. The stranded  data may overwrite the data or written to a new dataset.
__
  __
_*_mergestrand_*_ (menu option 'st')

__
  Merge two stranded datasets into a single new dataset, with the forward  dataset represented as a positive value, and the reverse dataset as a  negative value. Datapoints which contain values on both strands are  recorded as a simple difference (forward - reverse). This function may  not be appropriate with logarithmic or other datasets that include  negative values. Provide the indices of the two datasets as forward,  reverse. Metadata is not checked for validity.
__
  __
_*_center_*_ (menu option 'e')

__
  Center normalize the datapoints in a row by subtracting the mean or median of the datapoints. The range of datasets is requested or  provided by the --index option. Old values are replaced by new  values. This is useful for visualizing data as a heat map, for example.
__
  __
_*_new_*_ (menu option 'w')

__
  Generate a new dataset (column) which contains an identical value for  each datapoint (row). The value may be either requested interactively or  supplied using the --target option. This function may be useful for  assigning a common value to all of the data points before joining the  data file with another.
__
  __
_*_summary_*_ (menu option 'y')

__
  Write out a summary of collected windowed data file, in which the mean  for each of the data columns is calculated, transposed (columns become  rows), and written to a new data file. This is essentially identical to  the summary function from the biotoolbox analysis scripts  [Pod_map_relative_data_pl map_relative_data.pl] and [Pod_pull_features_pl pull_features.pl]. It assumes that each  dataset has start and stop metadata. The program will automatically  identify available datasets to summarize based on their name. In  interactive mode, it will request the contiguous range of start and  ending datasets to summarize. The contiguous datasets may also be  indicated using the --index option. By default, a new file using the  input file base name appended with '`_`summary' is written, or a  filename may be specified using the --out option.
__
  __
_*_export_*_ (menu option 'x')

__
  Export the data into a simple tab-delimited text file that contains no  metadata or header information. Non-values '.' are converted to   true nulls. If an output file name is specified using the --outfile  option, it will be used. Otherwise, a possible filename will be  suggested based on the input file name. If any modifications are  made to the data structure, a normal data file will still be written.  Note that this could overwrite the exported file if the output file name was specified on the command line, as both file write subroutines will  use the same name!
__
  __
_*_treeview_*_ (menu option 'T')

__
  Export the data into a format compatible with the Treeview program for  visualizing the data either as a heatmap or a dendrogram (when combined  with the Cluster program to generate the clusters or tree). Specify the  columns containing a unique name and the datasets to be analyzed (use  --index <**name>,<**start-stop>). Extraneous datasets are removed.  Additional manipulations on the datasets may be performed prior to  exporting. These may be chosen interactively or using the codes  listed below and specified using the --target option.
__
  __
{{{
  cg - median center features (genes)
  cd - median center datasets
  zd - convert dataset to Z-scores
  n0 - convert nulls to 0.0
}}}
  A simple Cluster data text file is written (default file name  "<**basename>.cdt"), but without the GWEIGHT column or EWEIGHT row. The  original file will not be rewritten.
__
  __
_*_rewrite_*_ (menu option 'W')

__
  Force the data file contents to be re-written. Useful if you want to  write an intermediate file during numerous interactive manipulations.  Consider this as a 'Save as...'.
__
  __
==AUTHOR==
{{{
 Timothy J. Parnell, PhD
 Howard Hughes Medical Institute
 Dept of Oncological Sciences
 Huntsman Cancer Institute
 University of Utah
 Salt Lake City, UT, 84112
}}}
This package is free software; you can redistribute it and/or modify it under the terms of the GPL (either version 1, or at your option, any later version) or the Artistic License 2.0.

