<?xml version="1.0" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>manipulate_datasets.pl</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link rev="made" href="mailto:_postfix@neige.apple.com" />
</head>

<body style="background-color: white">


<!-- INDEX BEGIN -->
<div name="index">
<p><a name="__index__"></a></p>
<!--

<ul>

	<li><a href="#name">NAME</a></li>
	<li><a href="#synopsis">SYNOPSIS</a></li>
	<li><a href="#options">OPTIONS</a></li>
	<li><a href="#description">DESCRIPTION</a></li>
	<li><a href="#functions">FUNCTIONS</a></li>
	<li><a href="#author">AUTHOR</a></li>
	<li><a href="#todo">TODO</a></li>
</ul>

-->


</div>
<!-- INDEX END -->

<p>
</p>
<h1><a name="name">NAME</a></h1>
<p>manipulate_datasets.pl</p>
<p>A progam to manipulate tab-delimited dataset files and avoid ExcHell.</p>
<p>
</p>
<hr />
<h1><a name="synopsis">SYNOPSIS</a></h1>
<p>manipulate_datasets.pl [--options ...] &lt;input_filename&gt;</p>
<pre>
  Options:
  --in &lt;input_filename&gt;
  --func [stat | reorder | delete | rename | sort | gsort | null | 
          duplicate | above | below | scale | pr | zscore | log2 | 
          delog2 | format | combine | subsample | ratio | diff | 
          normdiff | divide | subtract | export | treeview | 
          rewrite | center]
  --index &lt;integers&gt;
  --exp &lt;integer&gt;
  --con &lt;integer&gt;
  --target &lt;text&gt; or &lt;number&gt;
  --place [r | n]
  --except [y | n]
  --dir [i | d]
  --name &lt;text&gt;
  --out &lt;filename&gt;
  --(no)log
  --(no)gz
  --help
  --doc</pre>
<p>
</p>
<hr />
<h1><a name="options">OPTIONS</a></h1>
<p>The command line flags and descriptions:</p>
<dl>
<dt><strong><a name="in_input_filename" class="item">--in &lt;input_filename&gt;</a></strong></dt>

<dd>
<p>Provide the name of an input file. The file must be a tab-delimited text file, with each row 
specifiying a genomic feature (gene) or region, and each column representing identifying 
information or a dataset value. The first row should include the name for each column, e.g. the
name of the database dataset from which the values were collected.</p>
<p>If the file was generated using 'get_datasets.pl' and/or uses Tim's data file format, then each 
column will have metadata stored in a header comment line at the beginning of the file. This line
is prefixed with a # and is comprised of key=value pairs demarcated by semi-colons. Manipulations 
on the data in a column dataset will be added to this metadata and recorded upon file write.</p>
<p>If no metadata is present in the file, then it will be automatically generated with minimal 
information upon opening the file.</p>
<p>The input file may be compressed using the gzip program and recognized with the extension '.gz'. It 
will be automatically decompressed upon reading.</p>
</dd>
<dt><strong><a name="func_function" class="item">--func &lt;function&gt;</a></strong></dt>

<dd>
<p>The program is designed to be run interactively. However, single manipulations 
may be performed on single datasets by specifying a function name and any 
other required options. These functions include the following.</p>
<pre>

  stat
  reorder
  delete
  rename
  sort
  gsort
  null
  duplicate
  above
  below
  scale
  pr
  zscore
  log2
  delog2
  format
  combine
  subsample
  ratio
  diff
  normdiff
  divide
  subtract
  export
  treeview
  rewrite
  center</pre>
<p>Refer to the FUNCTIONS section for details.</p>
</dd>
<dt><strong><a name="index_integers" class="item">--index &lt;integers&gt;</a></strong></dt>

<dd>
<p>Provide the 0-based index number of the column(s) on which to perform the 
function(s). Multiple indices may also be specified using a comma delimited 
list without spaces. Ranges of contiguous indices may be specified using a 
dash between the start and stop. For example, '1,2,5-7,9' would indicate 
datasets '1, 2, 5, 6, 7, and 9'.</p>
</dd>
<dt><strong><a name="exp_num_integer" class="item">--exp | --num &lt;integer&gt;</a></strong></dt>

<dd>
<p>Specify the 0-based index number to be used for the experiment or numerator 
dataset with the 'ratio' or 'difference' functions. Both flags are aliases
for the same thing.</p>
</dd>
<dt><strong><a name="con_den_integer" class="item">--con | --den &lt;integer&gt;</a></strong></dt>

<dd>
<p>Specify the 0-based index number to be used for the control or denominator 
dataset with the 'ratio' or 'difference' functions. Both flags are aliases
for the same thing.</p>
</dd>
<dt><strong><a name="target_string_or_number" class="item">--target &lt;string&gt; or &lt;number&gt;</a></strong></dt>

<dd>
<p>Specify the target value when used with multiple functions, including the 
'scale', 'subtract', 'divide', and 'format' functions. Please refer to the 
function description for more information.</p>
</dd>
<dt><strong><a name="place_r_n" class="item">--place [r | n]</a></strong></dt>

<dd>
<p>Specify the placement of a transformed dataset. Two values are accepted ('r' 
or 'n'):</p>
<pre>

  - (r)eplace the original dataset with the new one
  - add as a (n)ew dataset</pre>
</dd>
<dt><strong><a name="except_y_n" class="item">--except [y | n]</a></strong></dt>

<dd>
<p>Specify what to do when a calculation encounters a 0 value. Two exception 
values are accepted:</p>
<pre>

  - (y)es, include 0 values in the calculation
  - (n)o, do not include 0 values in the calculation</pre>
<pre>

If this is not specified, the program will ask interactively if this occurs.</pre>
</dd>
<dt><strong><a name="dir_i_d" class="item">--dir [i | d]</a></strong></dt>

<dd>
<p>Specify the direction of a sort:</p>
<pre>

  - (i)ncreasing
  - (d)ecreasing</pre>
</dd>
<dt><strong><a name="name_string" class="item">--name &lt;string&gt;</a></strong></dt>

<dd>
<p>Specify a new dataset name when re-naming a dataset using the rename function 
from the command line. Also, when generating a new dataset using a defined 
function (--func &lt;function&gt;) from the command line, the new dataset will use 
this name.</p>
</dd>
<dt><strong><a name="out_filename" class="item">--out &lt;filename&gt;</a></strong></dt>

<dd>
<p>Optionally provide an alternative output file name. If no name is provided, then the input file 
will be overwritten with a new file. Appropriate extensions will be appended as necessary.</p>
</dd>
<dt><strong><a name="no_log" class="item">--(no)log</a></strong></dt>

<dd>
<p>Indicate whether the data is (not) in log2 space. This is required to ensure accurate mathematical 
calculations in some manipulations. This is not necessary when the log status is appropriately 
recorded in the dataset metadata.</p>
</dd>
<dt><strong><a name="no_gz" class="item">--(no)gz</a></strong></dt>

<dd>
<p>Indicate whether the output file should (not) be compressed. The appropriate extension will be 
added. If this option is not specified, then the compression status of the input file will be 
preserved.</p>
</dd>
<dt><strong><a name="help" class="item">--help</a></strong></dt>

<dd>
<p>Display the POD documentation using perldoc.</p>
</dd>
</dl>
<p>
</p>
<hr />
<h1><a name="description">DESCRIPTION</a></h1>
<p>This program allows some common mathematical and other manipulations on one
or more datasets in a datafile. The program is designed as a simple
replacement for common manipulations performed in a full featured
spreadsheet program, e.g. Excel, particularly with datasets too large to be
loaded, all in a conveniant command line program. The program is designed
to be operated primarily as an interactive program, allowing for multiple
manipulations to be performed. Alternatively, single manipulations may be
performed as specified using command line options. As such, the program can
be called in shell scripts.</p>
<p>Note that the datafile is loaded entirely in memory. For extremely large 
datafiles, e.g. binned genomic data, it may be best to first split the 
file into chunks (use <code>split_data_file.pl</code>), perform the manipulations, 
and recombine the file (use <code>join_data_file.pl</code>). This could be done 
through a simple shell script.</p>
<p>The program keeps track of the number of manipulations performed, and if 
any are performed, will write out to file the changed data. Unless an 
output file name is provided, it will overwrite the input file (NO BACKUP is
made!).</p>
<p>
</p>
<hr />
<h1><a name="functions">FUNCTIONS</a></h1>
<p>This is a list of the functions available for manipulating datasets. These may 
be selected interactively from the main menu (note the case sensitivity!), 
or specified on the command line using the --func option.</p>
<dl>
<dt><strong><a name="stat" class="item"><strong>stat</strong> (menu option 'a')</a></strong></dt>

<dd>
<p>Print some basic statistics for a dataset, including mean, 
median, standard deviation, min, and max. If 0 values are present,
indicate whether to include them (y or n)</p>
</dd>
<dt><strong><a name="reorder" class="item"><strong>reorder</strong> (menu option 'R')</a></strong></dt>

<dd>
<p>The datasets may be rewritten in a different order. The new order 
is requested as a string of index numbers in the desired order. 
Also, a dataset may be deleted by skipping its number or duplicated
by including it twice.</p>
</dd>
<dt><strong><a name="delete" class="item"><strong>delete</strong> (menu option 'D')</a></strong></dt>

<dd>
<p>One or more datasets may be selected for deletion.</p>
</dd>
<dt><strong><a name="rename" class="item"><strong>rename</strong> (menu option 'n')</a></strong></dt>

<dd>
<p>Assign a new name to a dataset. For automatic execution, use the --name 
option to specify the new name. Also, for any automatically executed 
function (using the --func option) that generates a new dataset, the 
dataset's new name may be explicitly defined with this option.</p>
</dd>
<dt><strong><a name="number" class="item"><strong>number</strong> (menu option 'b')</a></strong></dt>

<dd>
<p>Assign a number to each datapoint (or line), incrementing from 1 
to the end. The numbered dataset will be inserted after the requested 
dataset index.</p>
</dd>
<dt><strong><a name="sort" class="item"><strong>sort</strong> (menu option 'o')</a></strong></dt>

<dd>
<p>The entire data table is sorted by a specific dataset. The first
datapoint is checked for the presence of letters, and the data 
table is then sorted either asciibetically or numerically. If the 
sort method cannot be automatically determined, it will ask. The 
direction of sort, (i)ncreasing or (d)ecreasing, is requested.</p>
</dd>
<dt><strong><a name="gsort" class="item"><strong>gsort</strong> (menu option 'g')</a></strong></dt>

<dd>
<p>The entire data table is sorted by increasing genomic position, 
first by chromosome then by start position. These columns must exist 
and have recognizable names (e.g. 'chromo', 'chromosome', 'start').</p>
</dd>
<dt><strong><a name="null" class="item"><strong>null</strong> (menu option 'N')</a></strong></dt>

<dd>
<p>Toss datapoints (rows) that contain a null value in one or more 
datasets (columns). Some of the other functions may not work properly if
a non-value is present. If 0 values are present, indicate whether
to toss them (y or n). This may also be specified as a command line 
option using the --except flag.</p>
</dd>
<dt><strong><a name="duplicate" class="item"><strong>duplicate</strong> (menu option 'P')</a></strong></dt>

<dd>
<p>Toss datapoints with duplicate values. One or more datasets may be 
selected to search for duplicate values. Values are simply concatenated 
when multiple datasets are selected. Rows with duplicated values are 
deleted, always leaving the first row.</p>
</dd>
<dt><strong><a name="above" class="item"><strong>above</strong> (menu option 'A')</a></strong></dt>

<dd>
<p>Toss datapoints with values that are above a certain threshold value. 
One or more datasets may be selected to test values for the 
threshold. The threshold value may be requested interactively or 
specified with the --target option.</p>
</dd>
<dt><strong><a name="below" class="item"><strong>below</strong> (menu option 'B')</a></strong></dt>

<dd>
<p>Toss datapoints with values that are below a certain threshold value. 
One or more datasets may be selected to test values for the 
threshold. The threshold value may be requested interactively or 
specified with the --target option.</p>
</dd>
<dt><strong><a name="scale" class="item"><strong>scale</strong> (menu option 's')</a></strong></dt>

<dd>
<p>A dataset may be a median scaled as a means of normalization 
with other datasets. The current median of the dataset requested is
presented, and a new median target is requested. The dataset may 
either be replaced with the median scaled values or added as a new 
dataset. For automatic execution, specify the new median target 
with the --target option.</p>
</dd>
<dt><strong><a name="pr" class="item"><strong>pr</strong> (menu option 'p')</a></strong></dt>

<dd>
<p>A dataset may be converted to a percentile rank, whereby the
data values are sorted in ascending order and assigned a new value 
from 0..1 based on its rank in the sorted order. The dataset may 
either be replaced with the percentile rank or added as a new
dataset. The original order of the dataset is maintained.</p>
</dd>
<dt><strong><a name="zscore" class="item"><strong>zscore</strong> (menu option 'Z')</a></strong></dt>

<dd>
<p>Generate a Z-score for each value in a dataset. The Z-score is 
the number of standard deviations the value is away from the 
dataset's mean. Provides a simple measure of identifying significant 
outliers.</p>
</dd>
<dt><strong><a name="log2" class="item"><strong>log2</strong> (menu option 'l')</a></strong></dt>

<dd>
<p>A dataset may be converted to log base 2 values. The dataset
may either be replaced with the log2 values ar added as a new 
dataset.</p>
</dd>
<dt><strong><a name="delog2" class="item"><strong>delog2</strong> (menu option '2')</a></strong></dt>

<dd>
<p>A dataset that is currently in log2 space may be converted back to
normal base10 numbers. The dataset may either be replaced with the 
new values or added as a new dataset.</p>
</dd>
<dt><strong><a name="format" class="item"><strong>format</strong> (menu option 'f')</a></strong></dt>

<dd>
<p>Format the numbers of a dataset to a given number of decimal places. 
Acceptable numbers of decimal places include 0, 1, 2, or 3.
The dataset may either be replaced or added as a new dataset. For 
automatic execution, use the --target option to specify the number 
decimal places.</p>
</dd>
<dt><strong><a name="combine" class="item"><strong>combine</strong> (menu option 'c')</a></strong></dt>

<dd>
<p>Mathematically combine the data values in two or more datasets. The 
methods for combining the values include mean, median, min, max, 
stdev, or sum. The method may be specified on the command line 
using the --target option. The combined data values are added as a 
new dataset.</p>
</dd>
<dt><strong><a name="subsample" class="item"><strong>subsample</strong> (menu option 'U')</a></strong></dt>

<dd>
<p>Subsample a dataset. Datapoints within a dataset are chosen randomly
and the values reduced by one until the target sum is reached. This is
useful for working with enumerated datasets, e.g. tag counts from
Next-gen sequencing, where the sum of tags from two or more datasets
must be normalized to each other. This function assumes that the data
are positive integers; log2 datasets will not be used. Provide a
target sum to reach using the --target option. If this number is less
than or equal to the number of datasets in the file, then it is
assumed to be an index number and the sum of that dataset will be used
as the target. The subsampled dataset is always added as new dataset.</p>
</dd>
<dt><strong><a name="ratio" class="item"><strong>ratio</strong> (menu option 'r')</a></strong></dt>

<dd>
<p>A ratio may be generated between two datasets. The experiment and 
control datasets are requested and the ratio is added as a new
dataset. For log2 numbers, the control is subtracted from the
experiment. The log2 status is checked in the metadata for the 
specified datasets, or may be specified as a command line option, or
asked of the user.</p>
</dd>
<dt><strong><a name="diff" class="item"><strong>diff</strong> (menu option 'd')</a></strong></dt>

<dd>
<p>A simple difference is generated between two existing datasets. The 
values in the 'control' dataset are simply subtracted from the 
values in the 'experimental' dataset and recorded as a new dataset.
Prior to calculation, the sums of the two datasets are checked for 
equality, and, if not equal, the larger dataset is sub-sampled to 
match the smaller dataset. This function should be applied only to 
enumerated data sets (e.g. Illumina sequence tags) and not to 
microarray value data sets; it will not function on datasets in the 
log2 space. The indices for the experimental and control datasets 
may either requested from the user or supplied by the --exp and 
--con command line options.</p>
</dd>
<dt><strong><a name="normdiff" class="item"><strong>normdiff</strong> (menu option 'z')</a></strong></dt>

<dd>
<p>A normalized difference is generated between two existing datasets. 
The difference between 'control' and 'experimental' dataset values 
is divided by the square root of the sum (an approximation of the 
standard deviation). This is supposed to yield fewer false positives
than a simple difference (see Nix et al, BMC Bioinformatics, 2008).
Prior to calculation, the sums of the two datasets are checked for 
equality, and, if not equal, the larger dataset is sub-sampled to 
match the smaller dataset. This function should be applied only to 
enumerated data sets (e.g. Illumina sequence tags) and not to 
microarray value data sets; it will not function on datasets in the 
log2 space. The indices for the experimental and control datasets 
may either requested from the user or supplied by the --exp and 
--con command line options.</p>
</dd>
<dt><strong><a name="subtract" class="item"><strong>subtract</strong> (menu option 'u')</a></strong></dt>

<dd>
<p>Subtract a value from a dataset. A real number may be supplied, or the words
'mean' or 'median' may be entered as a proxy for those statistical
values of the dataset. The dataset may either be replaced or added
as a new one. For automatic execution, specify the number using the
--target option.</p>
</dd>
<dt><strong><a name="divide" class="item"><strong>divide</strong> (menu option 'v')</a></strong></dt>

<dd>
<p>Divide a value from a dataset. A real number may be supplied, or the words
'mean' or 'median' may be entered as a proxy for those statistical
values of the dataset. The dataset may either be replaced or added
as a new one. For automatic execution, specify the number using the
--target option.</p>
</dd>
<dt><strong><a name="center" class="item"><strong>center</strong> (menu option 'e')</a></strong></dt>

<dd>
<p>Center normalize the datapoints in a row by subtracting the mean or
median of the datapoints. The range of datasets is requested or 
provided by the --index option. Old values are replaced by new 
values. This is useful for visualizing data as a heat map, for example.</p>
</dd>
<dt><strong><a name="export" class="item"><strong>export</strong> (menu option 'x')</a></strong></dt>

<dd>
<p>Export the data into a simple tab-delimited text file that contains no 
metadata or header information. Non-values '.' are converted to  
true nulls. If an output file name is specified using the --outfile 
option, it will be used. Otherwise, a possible filename will be 
suggested based on the input file name. If any modifications are 
made to the data structure, a normal data file will still be written. 
Note that this could overwrite the exported file if the output file name
was specified on the command line, as both file write subroutines will 
use the same name!</p>
</dd>
<dt><strong><a name="treeview" class="item"><strong>treeview</strong> (menu option 'T')</a></strong></dt>

<dd>
<p>Export the data into a format compatible with the Treeview program for 
visualizing the data either as a heatmap or a dendrogram (when combined 
with the Cluster program to generate the clusters or tree). Specify the 
columns containing a unique name and the datasets to be analyzed (use 
--index &lt;name&gt;,&lt;start-stop&gt;). Prior to exporting, additional columns are 
deleted and the dataset columns are center normalized. A simple text 
file is written (default file name &quot;&lt;basename&gt;_tview.txt&quot;). No changes 
are made to the original file.</p>
</dd>
<dt><strong><a name="rewrite" class="item"><strong>rewrite</strong> (menu option 'W')</a></strong></dt>

<dd>
<p>Force the data file contents to be re-written. Useful if you want to 
write an intermediate file during numerous interactive manipulations, 
or if you want to quickly convert between binary data store file and 
text file formats via a commmand line tool (in which case, give the 
--out file name with the appropriate extension).</p>
</dd>
</dl>
<p>
</p>
<hr />
<h1><a name="author">AUTHOR</a></h1>
<pre>
 Timothy J. Parnell, PhD
 Howard Hughes Medical Institute
 Dept of Oncological Sciences
 Huntsman Cancer Institute
 University of Utah
 Salt Lake City, UT, 84112

</pre>
<p>This package is free software; you can redistribute it and/or modify
it under the terms of the GPL (either version 1, or at your option,
any later version) or the Artistic License 2.0.</p>
<p>
</p>
<hr />
<h1><a name="todo">TODO</a></h1>

</body>

</html>
